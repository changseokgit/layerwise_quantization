{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import module\n",
    "import vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.vgg16(pretrained=True)\n",
    "# model = vgg.vgg16(pretrained=True)\n",
    "model = torch.nn.DataParallel(model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_factor = [None for i in range(16)]\n",
    "pruning_factor = [3 for i in range(16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] layer pruning rate : 47.16435185185185\n",
      "[0] layer pruning rate : 14.0625\n",
      "[1] layer pruning rate : 96.240234375\n",
      "[1] layer pruning rate : 51.5625\n",
      "[2] layer pruning rate : 97.45008680555556\n",
      "[2] layer pruning rate : 64.84375\n",
      "[3] layer pruning rate : 99.20450846354166\n",
      "[3] layer pruning rate : 67.1875\n",
      "[4] layer pruning rate : 99.69991048177084\n",
      "[4] layer pruning rate : 83.203125\n",
      "[5] layer pruning rate : 99.94998508029514\n",
      "[5] layer pruning rate : 82.421875\n",
      "[6] layer pruning rate : 99.90251329210069\n",
      "[6] layer pruning rate : 81.640625\n",
      "[7] layer pruning rate : 99.94413587782118\n",
      "[7] layer pruning rate : 83.59375\n",
      "[8] layer pruning rate : 99.9945322672526\n",
      "[8] layer pruning rate : 73.4375\n",
      "[9] layer pruning rate : 99.99508327907986\n",
      "[9] layer pruning rate : 72.8515625\n",
      "[10] layer pruning rate : 99.99656677246094\n",
      "[10] layer pruning rate : 74.609375\n",
      "[11] layer pruning rate : 99.99949137369791\n",
      "[11] layer pruning rate : 58.984375\n",
      "[12] layer pruning rate : 99.99983045789931\n",
      "[12] layer pruning rate : 66.6015625\n",
      "[13] layer pruning rate : 100.0\n",
      "[13] layer pruning rate : 100.0\n",
      "[14] layer pruning rate : 100.0\n",
      "[14] layer pruning rate : 99.9267578125\n",
      "[15] layer pruning rate : 99.99997558593749\n",
      "[15] layer pruning rate : 100.0\n"
     ]
    }
   ],
   "source": [
    "# def weight_processing(model, quantization_factor, pruning_factor):\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "counter = 0\n",
    "total = 0\n",
    "sum = 0\n",
    "for module_name, layer in model.named_modules():\n",
    "    if type(layer) == torch.nn.modules.conv.Conv2d \\\n",
    "    or type(layer) == torch.nn.modules.linear.Linear or type(layer) == torch.nn.modules.batchnorm.BatchNorm2d or type(layer) == module.QuantizeConv2d or type(layer) == module.QuantizeLinear: \n",
    "        for layer_name, parameter in layer.named_parameters():\n",
    "            if quantization_factor[counter] != None:\n",
    "                state_dict[module_name + '.' + layer_name] = module.quantize(parameter, quantization_factor[counter])\n",
    "            if pruning_factor[counter] != None:\n",
    "                state_dict[module_name + '.' + layer_name] = state_dict[module_name + '.' + layer_name] * module.pruning(parameter, pruning_factor[counter])\n",
    "                sum += len(torch.nonzero(state_dict[module_name + '.' + layer_name]))\n",
    "                total += len(state_dict[module_name + '.' + layer_name].view(-1))\n",
    "                print('['+str(counter)+'] layer pruning rate : ' + str((1-(len(torch.nonzero(state_dict[module_name + '.' + layer_name])) / \n",
    "                                                                           len(state_dict[module_name + '.' + layer_name].view(-1))))*100))\n",
    "        counter += 1\n",
    "\n",
    "# print('total layer pruning rate : ' + str((1-sum/total)*100))\n",
    "\n",
    "model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weight_processing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0d7868942e97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print(model.state_dict()['module.features.0.weight'][0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mweight_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantization_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpruning_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(model.state_dict()['module.features.0.weight'][0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weight_processing' is not defined"
     ]
    }
   ],
   "source": [
    "# print(model.state_dict()['module.features.0.weight'][0])\n",
    "weight_processing(model, quantization_weight, pruning_weight)\n",
    "# print(model.state_dict()['module.features.0.weight'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
